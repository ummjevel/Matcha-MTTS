import whisper
from whisper.normalizers import EnglishTextNormalizer
import os
import jiwer
import torch
import json
import torch.multiprocessing as mp
from tqdm import tqdm
from jamo import h2j, j2hcj
import string

BATCH_SIZE = 32  # í•œ ë²ˆì— ì²˜ë¦¬í•  ì˜¤ë””ì˜¤ íŒŒì¼ ê°œìˆ˜
NUM_WORKERS = 4  # ë³‘ë ¬ ì²˜ë¦¬í•  í”„ë¡œì„¸ìŠ¤ ê°œìˆ˜

def init_whisper_model(model_size="medium", device="cuda"):
    """Whisper ëª¨ë¸ì„ ì´ˆê¸°í™”í•˜ëŠ” í•¨ìˆ˜ (GPU/CPU ì§€ì›)."""
    print(f"ğŸš€ Initializing Whisper model: {model_size} on {device}")
    model = whisper.load_model(model_size, device=device)
    print("âœ… Whisper model initialized successfully!")
    return model

def transcribe_audio(file_path, model, device, language):
    """Whisperë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜¤ë””ì˜¤ íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œ (GPU/CPU ì§€ì›)"""
    try:
        result = model.transcribe(file_path, language=language)  # âœ… ì–¸ì–´ ì„¤ì • ì¶”ê°€
        return result["text"].strip()  # ê³µë°± ì œê±° í›„ ë°˜í™˜
    except Exception as e:
        return f"[ERROR] Failed to transcribe {file_path}: {e}"

def calculate_wer(reference, hypothesis):
    """WER (Word Error Rate) ê³„ì‚°"""
    return jiwer.wer(reference, hypothesis)

def calculate_cer(reference, hypothesis):
    """CER (Character Error Rate) ê³„ì‚°"""
    return jiwer.cer(reference, hypothesis)

def remove_punctuation_and_whitespace(s):
    # Create a translation table that maps punctuation characters to None
    translator = str.maketrans('', '', string.punctuation)
    # Apply translation to remove punctuation
    no_punctuation = s.translate(translator)
    # Remove all whitespace characters
    no_whitespace = no_punctuation.replace(" ", "")
    return no_whitespace

def decompose_hangul(syllable):
    # Convert Hangul to jamo (initial, medial, final sounds)
    return j2hcj(h2j(syllable))

def evaluate_whisper(output_folder, reference_texts, model_size="medium", device="cuda", metric_type="wer", language="en"):
    """
    TTS ëª¨ë¸ì˜ ì¶œë ¥ ìŒì„±ì„ Whisperë¡œ ë³€í™˜ í›„, ë°°ì¹˜ ë‹¨ìœ„ë¡œ WER ë˜ëŠ” CER í‰ê°€ ìˆ˜í–‰í•˜ê³  JSONìœ¼ë¡œ ì €ì¥.

    :param output_folder: TTS ëª¨ë¸ì´ ìƒì„±í•œ ìŒì„± íŒŒì¼ì´ ì €ì¥ëœ í´ë”
    :param reference_texts: ["ì°¸ì¡° í…ìŠ¤íŠ¸1", "ì°¸ì¡° í…ìŠ¤íŠ¸2", ...] í˜•ì‹ì˜ ë¦¬ìŠ¤íŠ¸
    :param model_size: Whisper ëª¨ë¸ í¬ê¸° (small, medium, large)
    :param device: ì‹¤í–‰í•  ì¥ì¹˜ (cuda ë˜ëŠ” cpu)
    :param metric_type: í‰ê°€ ë°©ì‹ ì„ íƒ ("wer" ë˜ëŠ” "cer")
    :param language: Whisper ë””ì½”ë”© ì˜µì…˜ì—ì„œ ì‚¬ìš©í•  ì–¸ì–´ ("en", "ko", ë“±)
    """
    # mp.set_start_method("spawn", force=True)  # âœ… ë©€í‹°í”„ë¡œì„¸ì‹±ì„ spawn ë°©ì‹ìœ¼ë¡œ ì„¤ì •
    
    all_files = sorted([os.path.join(output_folder, f) for f in os.listdir(output_folder) if f.endswith(".wav")])

    # íŒŒì¼ ê°œìˆ˜ì™€ ì°¸ì¡° í…ìŠ¤íŠ¸ ê°œìˆ˜ê°€ ë‹¤ë¥´ë©´ ì˜¤ë¥˜ ì²˜ë¦¬
    if len(all_files) != len(reference_texts):
        raise ValueError(f"ğŸ“Œ íŒŒì¼ ê°œìˆ˜({len(all_files)})ì™€ ì°¸ì¡° í…ìŠ¤íŠ¸ ê°œìˆ˜({len(reference_texts)})ê°€ ë‹¤ë¦…ë‹ˆë‹¤.")

    # JSON ê²°ê³¼ ì €ì¥ ê²½ë¡œ ì„¤ì •
    json_output_path = os.path.join(output_folder, f"whisper_{language}.json")

    
    # ì „ì²´ ê²°ê³¼ ì·¨í•© ë° JSON ì €ì¥
    model = init_whisper_model(model_size, device)  # âœ… Whisper ëª¨ë¸ ì´ˆê¸°í™”
    normalizer = EnglishTextNormalizer()
    results = []
    
    for file_path, reference_text in zip(all_files, reference_texts):
        file_name = os.path.basename(file_path)

        # Whisperë¡œ í…ìŠ¤íŠ¸ ë³€í™˜ (ì–¸ì–´ ì„¤ì • ì¶”ê°€)
        hypothesis_text = transcribe_audio(file_path, model, device, language)

        if language=='en':
            hypothesis_text = normalizer(hypothesis_text.strip()).lower()
            reference_text = normalizer(reference_text.strip()).lower()
        elif language=='ko':
            hypothesis_text = decompose_hangul(remove_punctuation_and_whitespace(hypothesis_text.strip()))
            reference_text = decompose_hangul(remove_punctuation_and_whitespace(reference_text.strip()))

        # ì„ íƒí•œ í‰ê°€ ì§€í‘œì— ë”°ë¼ WER ë˜ëŠ” CER ê³„ì‚°
        if metric_type == "wer":
            score = calculate_wer(reference_text, hypothesis_text)
        elif metric_type == "cer":
            score = calculate_cer(reference_text, hypothesis_text)
        else:
            raise ValueError("Invalid metric_type. Use 'wer' or 'cer'.")

        results.append({
            "file": file_name,
            "reference_text": reference_text,
            "hypothesis_text": hypothesis_text,
            metric_type: score
        })

        print(f"{file_name} | {metric_type.upper()} ({language}): {score:.5f}")


    avg_score = sum([entry[metric_type] for entry in results]) / len(results) if results else 0

    final_output = {
        "language": language,
        "metric_type": metric_type,
        "average_score": avg_score,
        "results": results,
    }

    with open(json_output_path, "w", encoding="utf-8") as json_file:
        json.dump(final_output, json_file, ensure_ascii=False, indent=4)

    print(f"\nâœ… í‰ê·  {metric_type.upper()} ({language}): {avg_score:.5f}")
    print(f"ğŸ“‚ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {json_output_path}")

    return avg_score

if __name__ == "__main__":
    

    # í•œêµ­ì–´ TTS í‰ê°€ (CER, í•œêµ­ì–´)
    tts_output_folder_ko = "/path/to/tts_output_korean"
    reference_texts_ko = [
        "ì•ˆë…•í•˜ì„¸ìš”.",
        "í•œêµ­ì–´ í…ŒìŠ¤íŠ¸ ë¬¸ì¥ì…ë‹ˆë‹¤.",
        "ì´ ëª¨ë¸ì€ ë¬¸ì¥ì„ ë³€í™˜í•©ë‹ˆë‹¤."
    ]
    evaluate_whisper(tts_output_folder_ko, reference_texts_ko, model_size="medium", device="cuda", metric_type="cer", language="ko")

    # ì˜ì–´ TTS í‰ê°€ (WER, ì˜ì–´)
    tts_output_folder_en = "/path/to/tts_output_english"
    reference_texts_en = [
        "Hello world!",
        "This is a test sentence.",
        "How are you doing today?"
    ]
    evaluate_whisper(tts_output_folder_en, reference_texts_en, model_size="medium", device="cuda", metric_type="wer", language="en")
